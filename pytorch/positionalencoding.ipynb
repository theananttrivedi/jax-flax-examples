{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Positional Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_len = 100\n",
    "d_model = 512"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a matrix of 0s of 100 rows and 512 columns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "torch.Size([100, 512])\n"
     ]
    }
   ],
   "source": [
    "pe = torch.zeros(seq_len, d_model)\n",
    "print(pe)\n",
    "print(pe.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12., 13.,\n",
      "        14., 15., 16., 17., 18., 19., 20., 21., 22., 23., 24., 25., 26., 27.,\n",
      "        28., 29., 30., 31., 32., 33., 34., 35., 36., 37., 38., 39., 40., 41.,\n",
      "        42., 43., 44., 45., 46., 47., 48., 49., 50., 51., 52., 53., 54., 55.,\n",
      "        56., 57., 58., 59., 60., 61., 62., 63., 64., 65., 66., 67., 68., 69.,\n",
      "        70., 71., 72., 73., 74., 75., 76., 77., 78., 79., 80., 81., 82., 83.,\n",
      "        84., 85., 86., 87., 88., 89., 90., 91., 92., 93., 94., 95., 96., 97.,\n",
      "        98., 99.])\n",
      "torch.Size([100])\n"
     ]
    }
   ],
   "source": [
    "position = torch.arange(0, seq_len, dtype=torch.float)\n",
    "print(position)\n",
    "print(position.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### add a dimension along the column (axis 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.],\n",
      "        [ 1.],\n",
      "        [ 2.],\n",
      "        [ 3.],\n",
      "        [ 4.],\n",
      "        [ 5.],\n",
      "        [ 6.],\n",
      "        [ 7.],\n",
      "        [ 8.],\n",
      "        [ 9.],\n",
      "        [10.],\n",
      "        [11.],\n",
      "        [12.],\n",
      "        [13.],\n",
      "        [14.],\n",
      "        [15.],\n",
      "        [16.],\n",
      "        [17.],\n",
      "        [18.],\n",
      "        [19.],\n",
      "        [20.],\n",
      "        [21.],\n",
      "        [22.],\n",
      "        [23.],\n",
      "        [24.],\n",
      "        [25.],\n",
      "        [26.],\n",
      "        [27.],\n",
      "        [28.],\n",
      "        [29.],\n",
      "        [30.],\n",
      "        [31.],\n",
      "        [32.],\n",
      "        [33.],\n",
      "        [34.],\n",
      "        [35.],\n",
      "        [36.],\n",
      "        [37.],\n",
      "        [38.],\n",
      "        [39.],\n",
      "        [40.],\n",
      "        [41.],\n",
      "        [42.],\n",
      "        [43.],\n",
      "        [44.],\n",
      "        [45.],\n",
      "        [46.],\n",
      "        [47.],\n",
      "        [48.],\n",
      "        [49.],\n",
      "        [50.],\n",
      "        [51.],\n",
      "        [52.],\n",
      "        [53.],\n",
      "        [54.],\n",
      "        [55.],\n",
      "        [56.],\n",
      "        [57.],\n",
      "        [58.],\n",
      "        [59.],\n",
      "        [60.],\n",
      "        [61.],\n",
      "        [62.],\n",
      "        [63.],\n",
      "        [64.],\n",
      "        [65.],\n",
      "        [66.],\n",
      "        [67.],\n",
      "        [68.],\n",
      "        [69.],\n",
      "        [70.],\n",
      "        [71.],\n",
      "        [72.],\n",
      "        [73.],\n",
      "        [74.],\n",
      "        [75.],\n",
      "        [76.],\n",
      "        [77.],\n",
      "        [78.],\n",
      "        [79.],\n",
      "        [80.],\n",
      "        [81.],\n",
      "        [82.],\n",
      "        [83.],\n",
      "        [84.],\n",
      "        [85.],\n",
      "        [86.],\n",
      "        [87.],\n",
      "        [88.],\n",
      "        [89.],\n",
      "        [90.],\n",
      "        [91.],\n",
      "        [92.],\n",
      "        [93.],\n",
      "        [94.],\n",
      "        [95.],\n",
      "        [96.],\n",
      "        [97.],\n",
      "        [98.],\n",
      "        [99.]])\n",
      "torch.Size([100, 1])\n"
     ]
    }
   ],
   "source": [
    "position = position.unsqueeze(1)\n",
    "print(position)\n",
    "print(position.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.0000e+00, 9.6466e-01, 9.3057e-01, 8.9769e-01, 8.6596e-01, 8.3536e-01,\n",
      "        8.0584e-01, 7.7737e-01, 7.4989e-01, 7.2339e-01, 6.9783e-01, 6.7317e-01,\n",
      "        6.4938e-01, 6.2643e-01, 6.0430e-01, 5.8294e-01, 5.6234e-01, 5.4247e-01,\n",
      "        5.2330e-01, 5.0481e-01, 4.8697e-01, 4.6976e-01, 4.5316e-01, 4.3714e-01,\n",
      "        4.2170e-01, 4.0679e-01, 3.9242e-01, 3.7855e-01, 3.6517e-01, 3.5227e-01,\n",
      "        3.3982e-01, 3.2781e-01, 3.1623e-01, 3.0505e-01, 2.9427e-01, 2.8387e-01,\n",
      "        2.7384e-01, 2.6416e-01, 2.5483e-01, 2.4582e-01, 2.3714e-01, 2.2876e-01,\n",
      "        2.2067e-01, 2.1288e-01, 2.0535e-01, 1.9810e-01, 1.9110e-01, 1.8434e-01,\n",
      "        1.7783e-01, 1.7154e-01, 1.6548e-01, 1.5963e-01, 1.5399e-01, 1.4855e-01,\n",
      "        1.4330e-01, 1.3824e-01, 1.3335e-01, 1.2864e-01, 1.2409e-01, 1.1971e-01,\n",
      "        1.1548e-01, 1.1140e-01, 1.0746e-01, 1.0366e-01, 1.0000e-01, 9.6466e-02,\n",
      "        9.3057e-02, 8.9769e-02, 8.6596e-02, 8.3536e-02, 8.0584e-02, 7.7736e-02,\n",
      "        7.4989e-02, 7.2339e-02, 6.9783e-02, 6.7317e-02, 6.4938e-02, 6.2643e-02,\n",
      "        6.0430e-02, 5.8294e-02, 5.6234e-02, 5.4247e-02, 5.2330e-02, 5.0481e-02,\n",
      "        4.8697e-02, 4.6976e-02, 4.5316e-02, 4.3714e-02, 4.2170e-02, 4.0679e-02,\n",
      "        3.9242e-02, 3.7855e-02, 3.6517e-02, 3.5227e-02, 3.3982e-02, 3.2781e-02,\n",
      "        3.1623e-02, 3.0505e-02, 2.9427e-02, 2.8387e-02, 2.7384e-02, 2.6416e-02,\n",
      "        2.5483e-02, 2.4582e-02, 2.3714e-02, 2.2876e-02, 2.2067e-02, 2.1288e-02,\n",
      "        2.0535e-02, 1.9810e-02, 1.9110e-02, 1.8434e-02, 1.7783e-02, 1.7154e-02,\n",
      "        1.6548e-02, 1.5963e-02, 1.5399e-02, 1.4855e-02, 1.4330e-02, 1.3824e-02,\n",
      "        1.3335e-02, 1.2864e-02, 1.2409e-02, 1.1971e-02, 1.1548e-02, 1.1140e-02,\n",
      "        1.0746e-02, 1.0366e-02, 1.0000e-02, 9.6466e-03, 9.3057e-03, 8.9769e-03,\n",
      "        8.6596e-03, 8.3536e-03, 8.0584e-03, 7.7736e-03, 7.4989e-03, 7.2339e-03,\n",
      "        6.9783e-03, 6.7317e-03, 6.4938e-03, 6.2643e-03, 6.0430e-03, 5.8294e-03,\n",
      "        5.6234e-03, 5.4247e-03, 5.2330e-03, 5.0481e-03, 4.8697e-03, 4.6976e-03,\n",
      "        4.5316e-03, 4.3714e-03, 4.2170e-03, 4.0679e-03, 3.9242e-03, 3.7855e-03,\n",
      "        3.6517e-03, 3.5227e-03, 3.3982e-03, 3.2781e-03, 3.1623e-03, 3.0505e-03,\n",
      "        2.9427e-03, 2.8387e-03, 2.7384e-03, 2.6416e-03, 2.5483e-03, 2.4582e-03,\n",
      "        2.3714e-03, 2.2876e-03, 2.2067e-03, 2.1288e-03, 2.0535e-03, 1.9810e-03,\n",
      "        1.9110e-03, 1.8434e-03, 1.7783e-03, 1.7154e-03, 1.6548e-03, 1.5963e-03,\n",
      "        1.5399e-03, 1.4855e-03, 1.4330e-03, 1.3824e-03, 1.3335e-03, 1.2864e-03,\n",
      "        1.2409e-03, 1.1971e-03, 1.1548e-03, 1.1140e-03, 1.0746e-03, 1.0366e-03,\n",
      "        1.0000e-03, 9.6466e-04, 9.3057e-04, 8.9769e-04, 8.6596e-04, 8.3536e-04,\n",
      "        8.0584e-04, 7.7736e-04, 7.4989e-04, 7.2339e-04, 6.9783e-04, 6.7317e-04,\n",
      "        6.4938e-04, 6.2643e-04, 6.0430e-04, 5.8294e-04, 5.6234e-04, 5.4247e-04,\n",
      "        5.2330e-04, 5.0481e-04, 4.8697e-04, 4.6976e-04, 4.5316e-04, 4.3714e-04,\n",
      "        4.2170e-04, 4.0679e-04, 3.9242e-04, 3.7855e-04, 3.6517e-04, 3.5227e-04,\n",
      "        3.3982e-04, 3.2781e-04, 3.1623e-04, 3.0505e-04, 2.9427e-04, 2.8387e-04,\n",
      "        2.7384e-04, 2.6416e-04, 2.5483e-04, 2.4582e-04, 2.3714e-04, 2.2876e-04,\n",
      "        2.2067e-04, 2.1288e-04, 2.0535e-04, 1.9810e-04, 1.9110e-04, 1.8434e-04,\n",
      "        1.7783e-04, 1.7154e-04, 1.6548e-04, 1.5963e-04, 1.5399e-04, 1.4855e-04,\n",
      "        1.4330e-04, 1.3824e-04, 1.3335e-04, 1.2864e-04, 1.2409e-04, 1.1971e-04,\n",
      "        1.1548e-04, 1.1140e-04, 1.0746e-04, 1.0366e-04])\n",
      "torch.Size([256])\n"
     ]
    }
   ],
   "source": [
    "div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
    "print(div_term)\n",
    "print(div_term.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Positional Encoding\n",
    "def positional_encoding(seq_len, d_model):\n",
    "    pe = torch.zeros(seq_len, d_model)\n",
    "    position = torch.arange(0, seq_len, dtype=torch.float).unsqueeze(1)\n",
    "    div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
    "    pe[:, 0::2] = torch.sin(position * div_term)\n",
    "    pe[:, 1::2] = torch.cos(position * div_term)\n",
    "    return pe.unsqueeze(0)  # Shape: (1, seq_len, d_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.0000e+00,  1.0000e+00,  0.0000e+00,  ...,  1.0000e+00,\n",
       "           0.0000e+00,  1.0000e+00],\n",
       "         [ 8.4147e-01,  5.4030e-01,  8.2186e-01,  ...,  1.0000e+00,\n",
       "           1.0366e-04,  1.0000e+00],\n",
       "         [ 9.0930e-01, -4.1615e-01,  9.3641e-01,  ...,  1.0000e+00,\n",
       "           2.0733e-04,  1.0000e+00],\n",
       "         ...,\n",
       "         [ 3.7961e-01, -9.2515e-01, -6.2537e-01,  ...,  9.9995e-01,\n",
       "           1.0055e-02,  9.9995e-01],\n",
       "         [-5.7338e-01, -8.1929e-01,  2.8505e-01,  ...,  9.9994e-01,\n",
       "           1.0159e-02,  9.9995e-01],\n",
       "         [-9.9921e-01,  3.9821e-02,  9.5015e-01,  ...,  9.9994e-01,\n",
       "           1.0262e-02,  9.9995e-01]]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positional_encoding(seq_len, d_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
